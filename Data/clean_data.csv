,Post,Link,Sentence,WhoAnswered
0,689,https://piazza.com/class/l7102doc7aa3ob/post/689,"quiz. 9 - neural language models use word-embedding models in their training..hi , when taught in class it was mentioned that a by product of neural language models was the word embeddings but i do not remember word embeddings to be involved in training. please can someone confirm this. thanks",question
1,689,https://piazza.com/class/l7102doc7aa3ob/post/689,"yeah,i also have the same question.",s_answer
2,689,https://piazza.com/class/l7102doc7aa3ob/post/689,"yes, word embedding are not used to rain word2vec. we only use one-hot vectors and then learn word embeddings as the weights of the two-layer network.",i_answer
3,689,https://piazza.com/class/l7102doc7aa3ob/post/689,so the question in quiz 9 should be false? the answer was true for the question: neural language models use word-embedding models in their training.,followup_question
4,689,https://piazza.com/class/l7102doc7aa3ob/post/689,"no, that question is not about the two-layer network we used to learn word embeddings. that network itself never is used as a neural language modelf. the question is about neural language models that receive word embeddings as their input. in short, you need to pay attention to the network that the question is asking about.",feedback
5,663,https://piazza.com/class/l7102doc7aa3ob/post/663,regarding random shuffling between epochs while training.i am getting better mean f1 scores for both vanilla and averaged perceptron without random shuffling the dataset between epochs while training. is shuffling between epochs mandatory while training? can i train the perceptron without shuffling the dataset?,question
6,663,https://piazza.com/class/l7102doc7aa3ob/post/663,i also did not use shuffling. i was able to get above baseline f1,followup_question
7,663,https://piazza.com/class/l7102doc7aa3ob/post/663,"not mandatory, but see @661",i_answer
8,638,https://piazza.com/class/l7102doc7aa3ob/post/638,"feature extraction and classifying using one model.since i use tfidf for feature extraction, i need to keep the bag of words in the model for feature extraction in classifying right? does that mean i also need to store the idf for each word calculated in training and load it for classification? since the testing data need the same idf for the words in my bag of words. (unseen words will be discarded)",question
9,638,https://piazza.com/class/l7102doc7aa3ob/post/638,you could. another option would be to put the idf weights into your leaned weight vectors.,i_answer
10,608,https://piazza.com/class/l7102doc7aa3ob/post/608,"feature vector for unseen words.as we are creating one-hot encoding to convert reviews into features, how can i handle any unseen words in the test dataset? should i skip the word? or is there any other better alternative?",question
11,608,https://piazza.com/class/l7102doc7aa3ob/post/608,"ignoring an unknown word is probably the simplest solution. alternatively, you can devise features that could be triggered by both known and unknown words.",i_answer
12,593,https://piazza.com/class/l7102doc7aa3ob/post/593,"is a parallel corpus required for statistical machine translation?.please correct me if i am wrong but as per my understanding the noisy channel model for machine translation being a statistical model does require a parallel corpus, right?",question
13,593,https://piazza.com/class/l7102doc7aa3ob/post/593,"the question about parallel corpus for the language model, not mt.",i_answer
14,579,https://piazza.com/class/l7102doc7aa3ob/post/579,"smoothing transition probability matrix.what is meant by smoothing each row in the transition probability matrix? if we are generally dividing by the number of times the previous tag is in the corpus, are we adding 1 to that number?",question
15,579,https://piazza.com/class/l7102doc7aa3ob/post/579,"when there are many transitions whose probabilities are zero, it can also lead to dividing by zero. to avoid this, we add 1 to the numerator and some factor to the denominator. this is called laplace smoothing. we do not add 1 to that number. otherwise, the probability would become greater than 1",s_answer
16,579,https://piazza.com/class/l7102doc7aa3ob/post/579,"laplace smoothing was covered in the first week of class @490, and again last week (lecture 13 on october 4). smoothing each row just means treating each outgoing transition separately. that is, we perform smoothing on all the transitions from noun; separately, we perform smoothing on all the transitions from verb; and so on. because each of these is a separate probability distribution.",i_answer
17,541,https://piazza.com/class/l7102doc7aa3ob/post/541,hmm model.do we have to use forward-backward algorithm to learn the model as shown in the reference?,question
18,541,https://piazza.com/class/l7102doc7aa3ob/post/541,i also have this question as i came up with an iterative model that produced decent results,followup_question
19,541,https://piazza.com/class/l7102doc7aa3ob/post/541,see above.,feedback
20,541,https://piazza.com/class/l7102doc7aa3ob/post/541,"the forward-backward algorithm is for unsupervised learning. you do not need to do that, because the exercise provides labeled training data.",i_answer
21,536,https://piazza.com/class/l7102doc7aa3ob/post/536,"smoothing.instead of laplace smoothing, i am trying to use additive smoothing. still, i am not able to get good accuracy, leading not to be able to pinpoint the exact additive integer. is there any other way to do this?",question
22,536,https://piazza.com/class/l7102doc7aa3ob/post/536,"sophisticated smoothing could lead to a small improvement, but if the accuracy you are getting is not in the general range of the baseline or reference, then you probably have a bug or error, and finding and fixing that would lead to more improvement than fiddling with the smoothing method",i_answer
23,589,https://piazza.com/class/l7102doc7aa3ob/post/589,"how to use word tokens as features.in the overview of code assignment 4, it said that ""you may use the word tokens as features. "". professor said i can count words instead of using tf-idf. can anybody give me an example about how to transfer a review (i.e. a sequence of words/strings) into a vector (a sequence of numbers)?",question
24,589,https://piazza.com/class/l7102doc7aa3ob/post/589,is not it similar how we used word2vec features in coding assignment 2 ?,followup_question
25,589,https://piazza.com/class/l7102doc7aa3ob/post/589,"word2vec will transfer each word into a vector. in assignment 2, we transfer reviews/sentences into vectors in different ways (concatenation and average). i am not sure which one we should use. furthermore, training word2vec requires external library. i am not sure whether we are allowed to use it.",feedback
26,589,https://piazza.com/class/l7102doc7aa3ob/post/589,"using words as features, each word can be considered a feature, and the count of the word is the value. so a review like ""the omni is the best hotel in the world"" will have the following feature values: {'best': 1, 'hotel': 1, 'in': 1, 'is': 1, 'omni': 1, 'the': 3, 'world': 1} if you want to think of this as a fixed-length vector, then the length would be the entire vocabulary, and most values will be zero. notice how in the feature structure above, i silently changed 'the' to 'the', but kept 'omni' without change. this would be difficult to do programmatically, but this is one of the things to experiment with: is it helpful to change case? mess around with suffixes? do something with punctuation? is it helpful to develop features that are not words? for example, use word bigrams as features? are there any words that should be excluded from being used as features? i recommend starting with very simple features (say, just words), in order to get the basic logic of the perceptron working, once you have that, you can experiment to see how changes to features affect performance of the perceptron. no, word2vec is not allowed for this assignment.",i_answer
27,589,https://piazza.com/class/l7102doc7aa3ob/post/589,how do we handle out of vocabulary words in the above approach? if our training set does not contain a word encountered during testing is there a preferred way to handle them? or will the testing set not have words not encountered in training?,followup_question
28,589,https://piazza.com/class/l7102doc7aa3ob/post/589,@608,feedback
29,529,https://piazza.com/class/l7102doc7aa3ob/post/529,"dealing with unknown words in test data.. does ""ignoring emission prob"" mean considering it 1? eg. because for any tag, the prob of reaching it from a prev_tag is: prev_prob*emission_prob*transition_prob. which means the final prob will be prev_prob*transition_prob does ignoring mean considering emission prob as 1? thank you!",question
30,529,https://piazza.com/class/l7102doc7aa3ob/post/529,"yes, since any other value of the emissions probability would lead to some sort of influence of the overall state probability. for unseen words, i just set emission probability to 1 to account for that.",s_answer
31,529,https://piazza.com/class/l7102doc7aa3ob/post/529,"ignoring the emission is not the same as assuming the probability is one. mathematically, of course, multiplying a number by one is the same as leaving the number alone. but conceptually these are different. assuming all tags have a probability of 1 for emitting any unseen word is incoherent. instead, what we are doing is an algorithmic change: whereas for seen words, the viterbi decoding lattice (or matrix) registers the joint probability of the incoming path, latest transition, and emission, for unseen words the lattice registers the joint probability of the incoming path and latest transition. since it does the same for the entire column, the numbers are comparable. if you wanted to use an emission probability for unseen items, you would need to include that in your model. for example, you could divide your training data in order to estimate for each state the probability that it would generate an unseen token, and then build these estimates into the model.",i_answer
32,528,https://piazza.com/class/l7102doc7aa3ob/post/528,smoothing emission probability.why are we not smoothing emission probability?,question
33,528,https://piazza.com/class/l7102doc7aa3ob/post/528,"smoothing the emissions matrix would sacrifice efficiency due to its size. edit to add further explanation: you only need to smooth the emission matrix for unseen words. this is because smoothing the entire emissions matrix will assign too much probability to unseen events. that is, smoothing will result in a words having probabilities for tags they were not associated with in the training. thus, sacrificing accuracy in addition to efficiency. smoothing is typically done to either the transition or the emissions matrix. transition is typically chosen because some probabilities need to be reserved as unseen. for example, what if a noun/verb pair were never seen in the training data? does that mean a noun/verb pair will never appear while testing? take the sentence 'dogs lick'. the model would not be able to assign a non-zero transition probability between dogs/noun -> lick/verb. therefore, the absence of smoothing would lead to the verb being mistagged, thus impacting accuracy.",s_answer
34,528,https://piazza.com/class/l7102doc7aa3ob/post/528,"can we not apply smoothing while decoding? as a part of the model, we just save the frequencies and calculate the smoothed frequencies while decoding. eg. emission : p(word|tag) = (c(word, tag) + 1)/ (c(tag) + #uniquetags) for transition: eg. p(tag|prev_tag) = (c(prev_tag, tag) + 1)/ (c(prev_tag) + #uniquetags) cannot we calculate this while looping over all possible tags for a word when we are decoding? i think i have understood this wrong, pls help!",followup_question
35,528,https://piazza.com/class/l7102doc7aa3ob/post/528,"i suppose you could do it that way, although, i think it makes more sense to smooth while creating the matrices in `hmmlearn.py`. especially because in the learn program you will have unbridled access to all training data and only need to deal with words and tags in the given corpora, without worrying about unseen tags/words. if you are still unsure, you can always try it both ways and see what yields the best results!",feedback
36,528,https://piazza.com/class/l7102doc7aa3ob/post/528,"smoothing is part of the model: you calculate it once for each cell in the matrix when you build the model, and you are done. if you saved an unsmoothed model and want to use smoothed probabilities for decoding, then you would need to recalculate the same smoothed probabilities for every word in the test data. that is a lot of repetition of the same calculations, and it will slow down the decoder considerably.",feedback
37,528,https://piazza.com/class/l7102doc7aa3ob/post/528,"it is a tradeoff of runtime and accuracy. my best recommendation is to try it both ways: implement your model with and without smoothing on the emissions, measure runtime and accuracy for both options, and decide if the tradeoff is worthwhile. looking at the theory, smoothing the emission probabilities is expected to cause a substantial increase in runtime, because now you are calculating paths into every tag for every word, instead of throwing away most of the paths, it also has the potential for an improvement in accuracy, since you may run into a situation where context strongly suggests a tag but the current word was only seen with other tags. however, the improvement in accuracy is likely to be fairly modest, because if a word was seen with some tags but not others, then either the word is rare or the other tags are rare for that word.",i_answer
38,511,https://piazza.com/class/l7102doc7aa3ob/post/511,states vs observations.the parts of speech themselves are the states correct? which would make each word the observation? i am confused because there is a possibility our input data does not contain all possible part of speech tags and therefore will always incorrectly label any words belonging to that part of speech. is there a known list of part of speech tags we are supposed to use? or just use the ones from the training data?,question
39,511,https://piazza.com/class/l7102doc7aa3ob/post/511,"yes and yes. i am not sure if the data we are working with will have such cases. but if we do, then you are correct. it can happen that we do not see a tag in train dataset because of which we assign words belonging to that tag incorrectly when tagging test dataset. no there is no known list of part of speech tags. we should be using and learning model from the ones that are present in training data.",s_answer
40,506,https://piazza.com/class/l7102doc7aa3ob/post/506,is brill tagger a discriminative model or generative model?.,question
41,506,https://piazza.com/class/l7102doc7aa3ob/post/506,neither. the model does not output probabilities of tags or sequences of tags.,i_answer
42,506,https://piazza.com/class/l7102doc7aa3ob/post/506,its a rule based model right?,followup_question
43,506,https://piazza.com/class/l7102doc7aa3ob/post/506,not a pure rule-based model. it is a combination of a statistical tagger and a rule-based tagger that learns rules automatically from the data.,feedback
44,497,https://piazza.com/class/l7102doc7aa3ob/post/497,"finding open-class parts of speech.i am trying to find a good way to determine if a part of speech can be considered open-class. are there any general rules to follow when doing this? i tried calculating the average vocabulary size of each part of speech, and then classifying everything with a greater than average vocab size as open-class. however, this greatly reduced the algorithms accuracy, so i suspect this is the wrong way to go about it.",question
45,497,https://piazza.com/class/l7102doc7aa3ob/post/497,"the open/closed class distinction should not greatly improve or greatly decrease accuracy. remember, it only applies to unseen words, and there are not that many of those, so the effect should be rather small. from a good implementation of the open/closed class distinction you can expect an improvement of about 1 percentage point. if you see a great reduction in accuracy, then my first suspicion would be a bug in the implementation.",i_answer
46,490,https://piazza.com/class/l7102doc7aa3ob/post/490,"hmm smoothing.hi! i went through the algorithm in the references given to us and although there are tables showing the viterbi trellis for an example with and without smoothing, i do not particularly see how this smoothing is done. are we allowed to look for references on how smoothing is applied to the computation of transition probabilities or can you point some of the references we are allowed to use to this end? thanks!",question
47,490,https://piazza.com/class/l7102doc7aa3ob/post/490,"smoothing was covered in the first week of class, when talking about naive bayes. you can see descriptions of the process in jurafsky and martin, chapter 4, pages 5–6, and in manning, raghavan and schutze, chapter 13, page 260. smoothing for hmm works exactly the same way. you just need to make sure to separately smooth each row in the matrix, since each row represents an independent probability distribution. you are allowed to consult references. what is not allowed is consulting implementations (or texts that specifically describe an implementation).",i_answer
48,484,https://piazza.com/class/l7102doc7aa3ob/post/484,"question about initial probabilties.are initial probabilities calculated considering only the first word in a sentence, or do we use the markov assumption and consider each word in the sentence as a potential starting point? if it is the latter, then would every word in the sentence be considered as a potential starting point except the very last word in the sentence?",question
49,484,https://piazza.com/class/l7102doc7aa3ob/post/484,i might be wrong but i do not think the initial probability distribution has anything to do with the position of the words. i think we just calculate that depending upon the number of occurrences in the corpus.,s_answer
50,484,https://piazza.com/class/l7102doc7aa3ob/post/484,"by initial probabilities, i assume you mean what jurafsky and martin call “an initial probability distribution over states” (top of page 9). this is the probability distribution of the first state in a sentence. to estimate the initial probability of state x, just take the number of sentences that start with x, and divide by the total number of sentences. do not forget to apply smoothing. an alternative approach is the algorithm presented in the written exercises that were distributed on blackboard. add a special initial state that is not associated with any observations, and assume that each sentence starts with a transition from that initial state to the first word-producing state. then the initial probability distribution from the previous paragraph becomes just another row in the transition matrix. the two approaches are mathematically equivalent.",i_answer
51,443,https://piazza.com/class/l7102doc7aa3ob/post/443,"can anyone explain q1?.why chi-squared test is the most suitable hypothesis test to know if gender has anything to do with political party preference (democrats, republicans, etc)? why not t-test? what is the difference between chi-squared test and t-test?",question
52,443,https://piazza.com/class/l7102doc7aa3ob/post/443,"the chi-squared test is used when we have categorical variables (here gender and political party preference). however, the t-test is used when we have quantitative variables (like to compare the mean of 2 samples).",i_answer
53,348,https://piazza.com/class/l7102doc7aa3ob/post/348,"using cuda.when implementing fnn and rnn, do we have to cast tensors to a cuda type to run on gpu? thank you!",question
54,348,https://piazza.com/class/l7102doc7aa3ob/post/348,yes,i_answer
55,254,https://piazza.com/class/l7102doc7aa3ob/post/254,"quiz question - 9.hi, question 9: choice 'it is efficient to learn long-term dependencies through time' is considered as a wrong option in the rubrics. but rnn's are known for long term dependencies over time through their dynamic system. normalized rnn's are even more capable of unfolding long term dependences over time. here are some relevant papers: 1. 2. 3.",question
56,254,https://piazza.com/class/l7102doc7aa3ob/post/254,"i second this! compared to fnn, rnns are know for capturing long term dependencies. the question does not specify whether rnns being compared to lstms or transformers.",s_answer
57,254,https://piazza.com/class/l7102doc7aa3ob/post/254,"the key is the word ""efficient"". rnn can model the long-term dependencies but computationally the process is not efficient and that is why gated rnn is developed.",i_answer
58,245,https://piazza.com/class/l7102doc7aa3ob/post/245,"not using grad.zero() to initialize the gradients after each iteration?.if we do not use grad.zero() and allow the gradients to accumulate, can it be useful in some cases?",question
59,245,https://piazza.com/class/l7102doc7aa3ob/post/245,i have not seen such a case personally but likely there is a reason behind the pytorch designer team that set it to be accumulative.,i_answer
60,241,https://piazza.com/class/l7102doc7aa3ob/post/241,"vague quiz 3 question.during the quiz there was this t/f question that i felt was vague:in rnn, the weights during each time step is shared.i thought that this question was asking if the neurons are using the same weights at each time step, which i thought was false since we should be updating the weights and hence, using different weights at each time step. the correct answer for this question was true. i believe that this question is asking whether we are calculating the new weight at time t using the weights from time t-1. am i the only who felt that the question was a little misleading?",question
61,241,https://piazza.com/class/l7102doc7aa3ob/post/241,"weights during rnn backprop are not updated on each time step, since backprop happens after the full forward computation is done (i believe from slide 9 of lecture 6). that means that the same weights would actually be shared. therefore, i do not think this question was misleading. (for rnns, a ""timestep"" refers to the position of an individual rnn cell, not a full forward-backward computation.)",s_answer
62,227,https://piazza.com/class/l7102doc7aa3ob/post/227,"cosine similarity numerical.i just wanted to know if this is correct question : find cosine similarity for : x1 = (3,4) x2 = (1,0) solution : x*y cosine similarity = ________ ||x|| ||y|| 3*1 + 4*0 ___________________________ = 3/5 = 0.6 sqrt((3*3+4*4)x(1*1+0*0)) can you please confirm this calculation or is it incomplete as do we consider the euclidean distance instead, by assuming center to be the origin? (3-0)*(1-0) + (4-0)*(0-0) ___________________________ = 3/2 = 0.6 sqrt((3*3+4*4)x(1*1+0*0)) do we consider the center to be (0,0) always, as it was not mentioned by default in the question in the quiz? thank you",question
63,227,https://piazza.com/class/l7102doc7aa3ob/post/227,the first computation is correct and the definitions of dot product and vector norm are both independent of the center of coordinate.,i_answer
64,227,https://piazza.com/class/l7102doc7aa3ob/post/227,thank you so do we consider the euclidean distance while taking the magnitudes in the denominator is what i am confused about ? i wanted to know if magnitude of vectors i.e. |a| and |b| in the formula are absolute vectors or distances from a point of consideration?,followup_question
65,85,https://piazza.com/class/l7102doc7aa3ob/post/85,tf-idf.should i run tf-idf and extract features treating entire dataset as corpus? or by doing it classwise??,question
66,85,https://piazza.com/class/l7102doc7aa3ob/post/85,you should do it on the entire dataset.,i_answer
67,84,https://piazza.com/class/l7102doc7aa3ob/post/84,"gradient descent vs perceptron algorithms.i want to verify my understanding is correct. the perceptron algorithm describes the full process of assigning random weights, then viewing examples from training data, adjusting weights, etc. gradient descent is a specific optimization technique that can be used to adjust weights. so one could replace the ""vanilla"" method of adjusting weights from the perceptron algorithm with gradient descent?",question
68,84,https://piazza.com/class/l7102doc7aa3ob/post/84,"gradient descent is a general optimization algorithm and works for all functions that are differentiable. so, you can use it for many problems. it may be possible to come up with a solution for perception using gradient descent, too. perceptron algorithm is specific to the perception model.",i_answer
69,79,https://piazza.com/class/l7102doc7aa3ob/post/79,"lemmatization based on pos tag.the ntlk lemmatizer will not lemmatize ""wearing"" to ""wear"" unless explicit mentioned to considered it as a word, because the default tag is ""noun"" . is this lemmatization acceptable?",question
70,79,https://piazza.com/class/l7102doc7aa3ob/post/79,"i think so. you do not have to look at the specific cases of lemmatization otherwise it would be too much work, the default should suffice.",i_answer
71,79,https://piazza.com/class/l7102doc7aa3ob/post/79,"does lemmatization take a long time for 100000 reviews? in my case, the code is running for a while now, not sure if its common.",followup_question
72,58,https://piazza.com/class/l7102doc7aa3ob/post/58,why do we use perplexity and not raw probability to evaluate language models?.why do we use perplexity and not raw probability to evaluate language models?,question
73,58,https://piazza.com/class/l7102doc7aa3ob/post/58,"we will cover this topic when we cover language models. in short, because raw probability values are between 0 and 1 and does not convey an intuitive measure.",i_answer
74,39,https://piazza.com/class/l7102doc7aa3ob/post/39,"bow dictionary.does the dictionary need to be ordered in some way for bow to be used ? if so, is there any advantage to ordering it in alphabetical way ?",question
75,39,https://piazza.com/class/l7102doc7aa3ob/post/39,"ordering should not have any effect when building bow. unless you are dealing with billions of reviews, even in such case ordering your bow w.r.t word frequency( to reduce document traversal) might not have any significant effect.",s_answer
76,39,https://piazza.com/class/l7102doc7aa3ob/post/39,"got it, thanks !",followup_question
77,20,https://piazza.com/class/l7102doc7aa3ob/post/20,bag of words.how is a model which encounters a vector space representation of word vs document which is extremely sparse affected? what can be done to handle the negative effects on the model?,question
78,20,https://piazza.com/class/l7102doc7aa3ob/post/20,"in this case, the feature might not be a good representation of the document. you can expand the vocabulary to make the representation less sparse, at the cost of increasing the dimension of the vector. bow is a simple model, it suffers from the problems like the one you mentioned inherently. it is useful in some simple applications, when you do not have to deal with the outliers.",i_answer
79,22,https://piazza.com/class/l7102doc7aa3ob/post/22,tf-idf.why do we use a logarithm for idf? how does it benefit mathematics,question
80,22,https://piazza.com/class/l7102doc7aa3ob/post/22,"it suppresses large values to avoid making some feature values that correspond to infrequent ones too large. in practice, this has impression been found to be helpful.",i_answer
81,37,https://piazza.com/class/l7102doc7aa3ob/post/37,tokenize review before lemmatization.should we tokenize review_body before lemmatizing the sentence?,question
82,37,https://piazza.com/class/l7102doc7aa3ob/post/37,lemmatization is performed on a word-level basis.,i_answer
83,37,https://piazza.com/class/l7102doc7aa3ob/post/37,should the lemmatized review (after lemmatizing) be a python list of lemmatized words? thanks!,followup_question
84,37,https://piazza.com/class/l7102doc7aa3ob/post/37,"i understand it is on a word level basis, but using the python list of lemmatized words as input to sklearn, tfidfvectorizer cannot output the matrix. do i reconstruct the lemmatized word list to a sentence?",feedback
85,37,https://piazza.com/class/l7102doc7aa3ob/post/37,nltk has a built-in function that you can use but you are free to use your own developed function if it leads to improved performance.,feedback
86,37,https://piazza.com/class/l7102doc7aa3ob/post/37,"are you referring to wnl.lemmatize? it could not lemmatize whole sentences when i tried it, and i had to tokenize it first. then, tfidfvectorizer only accepts strings (strings with spaces were common use cases online)",feedback
87,37,https://piazza.com/class/l7102doc7aa3ob/post/37,you can make a string from words after lemmatization.,feedback
88,86,https://piazza.com/class/l7102doc7aa3ob/post/86,contractions library.do you all have any other recommendations besides the standard contractions library (with which you can do contractions.fix)? i noticed online that there are issues with it when dealing with ambiguity in tense and all. or do you all think this can be safely ignored with respect to the performance of the various models?,question
89,86,https://piazza.com/class/l7102doc7aa3ob/post/86,"the standard library should be fine for a decent performance but if you think you can do better, you can use an improved approach on top of it.",i_answer
90,101,https://piazza.com/class/l7102doc7aa3ob/post/101,performing lemmatization on the whole of reviews dataset.the lemmatization process is taking a long time. has anyone faced this issue? anything that can done to improve the runtime?,question
91,101,https://piazza.com/class/l7102doc7aa3ob/post/101,"running time depends on your machine, too. but generally, it is not superfast and we do not penaliz you if your running time is long.",i_answer
92,101,https://piazza.com/class/l7102doc7aa3ob/post/101,"tried running the code on google collab, but it is running for more than 25mins now. just wanted to know if it is common for such a long runtime or if there is some mistake in the code.",followup_question
93,101,https://piazza.com/class/l7102doc7aa3ob/post/101,"i am on colab as well, but lemmatizing (including nouns, verbs and adjectives) takes like 2 mins",feedback
94,101,https://piazza.com/class/l7102doc7aa3ob/post/101,it can be because you are using a non-sparse matrix format. tfidf features can be stored as sparse matrices.,feedback
95,116,https://piazza.com/class/l7102doc7aa3ob/post/116,"different preprocessing steps for each algorithm.hello, can we have different preprocessing steps for different algorithms given we explain the steps in detail in report and including/excluding some preprocessing steps improved scores. or is it required that all data go through same set of preprocessing steps and then each algorithm is evaluated on it?",question
96,116,https://piazza.com/class/l7102doc7aa3ob/post/116,"yes, that is possible.",i_answer
97,317,https://piazza.com/class/l7102doc7aa3ob/post/317,"what is the number of fnn output layer.like we set first hidden layer as 50, the second hidden layer is 10. but how about the output layer? is it 5 or 1?",question
98,317,https://piazza.com/class/l7102doc7aa3ob/post/317,it should be 5 since it is a 5 class classification problem.,i_answer
99,317,https://piazza.com/class/l7102doc7aa3ob/post/317,"when i set the output layer as 5, i got runtimeerror: 0d or 1d target tensor expected, multi-target not supported does anyone know why?",followup_question
100,317,https://piazza.com/class/l7102doc7aa3ob/post/317,"since it is a 5-class multiclassification problem, the output of the neural network should be in the range between 0 to 4. but in our data, we have ratings between 1 to 5. this is the problem.",feedback
101,347,https://piazza.com/class/l7102doc7aa3ob/post/347,"input to rnn.will the input of the rnn be a word embedding aka a vector of size (300,)? if yes then would not hidden state also have to be 300 ?",question
102,347,https://piazza.com/class/l7102doc7aa3ob/post/347,"i suppose the hidden layer to have a shape like (num_layers, time_steps(i.e. 20), output_embedding) now the output embedding can be of your choice. just like the hidden layer output dimensions of mlp",s_answer
103,347,https://piazza.com/class/l7102doc7aa3ob/post/347,what is 'num_layers' in the above student's answer?,followup_question
104,358,https://piazza.com/class/l7102doc7aa3ob/post/358,training on rnn and gru too slow even using gpu.do we need to iterate through entire training dataset in one epoch? it takes about 1 hr to run 10 epoch for rnn which i directly follow the tutorial in the pdf and add a optimizer. but in the tutorial seems only train on one document for one epoch. even worse for gru which i wait 20 minutes and does not finish one epoch. is there suggestion to solve this problem? by the way i choose hidden size as 30,question
105,358,https://piazza.com/class/l7102doc7aa3ob/post/358,solved. find out add batchsize can speed it up.,s_answer
106,358,https://piazza.com/class/l7102doc7aa3ob/post/358,"could you please elaborate on how you used batched processing with rnn? i am kind of stuck here. not sure how to change the dimensions of the input, hidden and output layers when using batches.",followup_question
107,358,https://piazza.com/class/l7102doc7aa3ob/post/358,"just same as the fnn, we do not need to modify the dimensions except hidden state, as the tutorial initial it as (1,hiddensize), so i changed it to (batchsize,hiddensize)",feedback
108,358,https://piazza.com/class/l7102doc7aa3ob/post/358,"oh okay but i was thinking that the shape in rnn input would be different than that for the fnn as in fnn we were concatenating the w2v vectors resulting in each sequence of shape (3000) while in rnn i thought we are not concatenating but passing each word vector one by one for a given sequence thus each input sequence having the shape (20, 300) instead of (6000) which would have been if we concatenated the vectors.",feedback
109,358,https://piazza.com/class/l7102doc7aa3ob/post/358,"actually the shape should be (batchsize,20,300)",feedback
110,358,https://piazza.com/class/l7102doc7aa3ob/post/358,"yeah, i got that but was confused about the shape of the hidden layer whether that too should be (batch_size, 20, 300).",feedback
111,358,https://piazza.com/class/l7102doc7aa3ob/post/358,i am also having the same doubt,feedback
112,362,https://piazza.com/class/l7102doc7aa3ob/post/362,does anyone have the same problem that rnn and gru loss does not decrease?.i trained for 100 epoch and it keeps at a very high value same as beginning. stuck here and debug for hours and did not see a difference. does anyone have the same problem? any suggestion?,question
113,362,https://piazza.com/class/l7102doc7aa3ob/post/362,maybe change the learning rate and see if it helps.,i_answer
114,362,https://piazza.com/class/l7102doc7aa3ob/post/362,"i had the same issue. in my case, adding loss.backward() after loss = criterion worked.",followup_question
115,871,https://piazza.com/class/ky7ls2h92kpwe/post/871,question 47. bert cannot be fine-tuned to abstractive summarization because it could fill the masked words but cannot generate a summary with a decoder? thanks a lot!,question
116,871,https://piazza.com/class/ky7ls2h92kpwe/post/871,for abstractive sumarization you need an autoregressive model. bert is an mlm and does not do autoregressive generation.,i_answer
117,870,https://piazza.com/class/ky7ls2h92kpwe/post/870,"question 32. can anyone explain why abstractive summarization could be a use case of nli? and for fact verification, we could have a context and a fact sentence, which we could do nli in my opinion? thank you very much!",question
118,870,https://piazza.com/class/ky7ls2h92kpwe/post/870,that should be indeed fact verification. i just corrected that in the system.,i_answer
119,868,https://piazza.com/class/ky7ls2h92kpwe/post/868,"question 15. i am confused about this question. in the class, the example of syntactic ambiguity is that ""flying planes can be dangerous"". and professor ron mentioned that words in this string have one meaning but the combination of words has more than one meaning. so i guess my choice also makes sense?",question
120,868,https://piazza.com/class/ky7ls2h92kpwe/post/868,"syntax is a matter of sentence structure, as explained in the introduction class, the parsing class, and the associated reading. while it is true that different structures often correspond to different meanings, this is not always the case. for example, ""(a cat and a dog) and a mouse"" has a very similar meaning to ""a cat and (a dog and a mouse)"".",i_answer
121,868,https://piazza.com/class/ky7ls2h92kpwe/post/868,"ok, i thought the one more meaning you mentioned in class is the definition. from the explanation you gave, it makes more sense! thank you.",followup_question
122,594,https://piazza.com/class/ky7ls2h92kpwe/post/594,how to handle oovs?.what are the different ways to handle oov (out of vocabulary) words?,question
123,594,https://piazza.com/class/ky7ls2h92kpwe/post/594,"we talked about that in the ""subword representation, contextualized representation"" lecture. please refer to those slides.",i_answer
124,590,https://piazza.com/class/ky7ls2h92kpwe/post/590,"overfitting?.hi, in this loss graph, the validation loss increases, but validation accuracy also increases. is this overfitting or just the prediction power of classes shifting?",question
125,590,https://piazza.com/class/ky7ls2h92kpwe/post/590,i am also getting something like this. is this actually an issue or can we get around this? any suggestions?,followup_question
126,590,https://piazza.com/class/ky7ls2h92kpwe/post/590,refer this,s_answer
127,576,https://piazza.com/class/ky7ls2h92kpwe/post/576,with more epoch validation accuracy is going down for dev set.why is that with more epochs the validation accuracy goes down for dev set ? what is the reason behind it? should i decrease the epoch value ? will it work better on test set ?,question
128,576,https://piazza.com/class/ky7ls2h92kpwe/post/576,that is the case for me too.,followup_question
129,576,https://piazza.com/class/ky7ls2h92kpwe/post/576,"this is the case of overfitting. over a certain number of epochs, the model starts to capture the noise in the training data and thus resulting in low accuracy in validation data.",s_answer
130,576,https://piazza.com/class/ky7ls2h92kpwe/post/576,you can try using earlystopping.,followup_question
131,576,https://piazza.com/class/ky7ls2h92kpwe/post/576,exactly,feedback
132,570,https://piazza.com/class/ky7ls2h92kpwe/post/570,"knn classification k = 1.is there a situation that using k = 1 is acceptable for knn. if k=1 gives the highest model performance on an “unseen” dev set, does it make sense to use k=1?",question
133,570,https://piazza.com/class/ky7ls2h92kpwe/post/570,"in that case you do not really need to think about using an ml model. if your real world data maps 1:1 to your train data, you might as well write a sql(elasticsearch would be better) query with training data as your database.",s_answer
134,544,https://piazza.com/class/ky7ls2h92kpwe/post/544,"inter-rather agreement vs inter-annotator agreement.hello,are these two terms the same thing — just iaa being a bit more specified for annotation? otherwise i have seen them be used interchangeably in many places, and are measures with the same method’s, like cohen’s kappa.",question
135,544,https://piazza.com/class/ky7ls2h92kpwe/post/544,same,i_answer
136,487,https://piazza.com/class/ky7ls2h92kpwe/post/487,"tensorflow or pytorch?.hello, tensorflow and pytorch seem to be the most popular ml libraries today. is there any recommendation on what is more suitable for nlp tasks? in terms of learning curve, industry-relevance, ease of deployment, etc.? thanks.",question
137,487,https://piazza.com/class/ky7ls2h92kpwe/post/487,pytorch,followup_question
138,487,https://piazza.com/class/ky7ls2h92kpwe/post/487,"historically, pytorch had a better performance on recursive networks (e.g. lstm) that were dominant before transformers, but they are both pretty good now. i personally use pytorch as it feels more natural to me but tf2.0 is also pretty mature and powerful once you get into the mindset. i cannot comment about industry usage. so just pick one.",i_answer
139,382,https://piazza.com/class/ky7ls2h92kpwe/post/382,"pos tagging: preprocessing.is preprocessing generally done with pos tagging? such as removing stop words, removing punctuations, or stemming to name a few.thanks",question
140,382,https://piazza.com/class/ky7ls2h92kpwe/post/382,"i do not think we are supposed to do this because stopwords too have a part of speech associated with them. so we are needed to predict that. also, these stopwords and predictions define the probability of certain pos, if you remove them you model will not take this into account. certain pos can have more probability to end or start the sentence than others. removing stopwords, punctuation etc will ignore this. i think stemming too should not be done as it can change the pos tag. please correct me if i am wrong.",s_answer
141,268,https://piazza.com/class/ky7ls2h92kpwe/post/268,"does encoder (decoder) imply a specific model or just a general speaking of sentence representation?.in the class, prof. chen talked about bi-encoder & cross-encoder, and i am confused that if the encoder is a specific model or it could be any kind of sentence representation method? for example, the output of lstm, or cnn, or self-attention? since the key word ""encoder"" (and ""decoder"") was mentioned several times during the lecture, i want to figure out what it really means. thanks in advance!",question
142,268,https://piazza.com/class/ky7ls2h92kpwe/post/268,"any kind of sequence encoders: cnns, lstms, self-attention encoders or transformers (multi-head attention). note that cross-encoder architectures usually use attention encoders nowadays.",i_answer
143,255,https://piazza.com/class/ky7ls2h92kpwe/post/255,"vanishing gradient.do all models that use gradient descent, have a vanishing gradient problem?",question
144,255,https://piazza.com/class/ky7ls2h92kpwe/post/255,"it depends on the depth of the neural networks. consider a one-layer nn, there is no vanishing gradient problem. however, for a very depth model (consider a 100-layer fully connected nn), it is higher chance that there is a vanishing gradient problem.",i_answer
145,251,https://piazza.com/class/ky7ls2h92kpwe/post/251,query regarding rnns.do rnns have a fixed vocabulary limitation ?,question
146,251,https://piazza.com/class/ky7ls2h92kpwe/post/251,"depends. an rnn is simply a sequence model. if your input can handle oov tokens (eg. passing fasttext embs to rnn), then then the answer is no. if you are simply using something like word2vec or one hot then yes.",s_answer
147,243,https://piazza.com/class/ky7ls2h92kpwe/post/243,"convex optimization problem.hello,can you explain what is meant by saying an optimization problem is convex? and how can we actually determine whether an optimization problem is convex?",question
148,243,https://piazza.com/class/ky7ls2h92kpwe/post/243,"convex optimization means you are minimize a convex function. if you minimize a convex function, each local minima is global minima. for example, if you want to use a quadratic function to fit a series of data points, choosing the parameter of the quadratic function is a convex optimization problem.",i_answer
149,103,https://piazza.com/class/ky7ls2h92kpwe/post/103,naive bayes.we are adding logarithmic probabilities instead of multiplying conditional probabilities because it can result in floating-point underflow. what is floating-point underflow? any example?,question
150,103,https://piazza.com/class/ky7ls2h92kpwe/post/103,"since probabilities lie between 0 and 1, multiplying a lot of them can result in very small numbers that the data type cannot represent. arithmetic underflow can occur when the true result of a floating point operation is smaller in magnitude (that is, closer to zero) than the smallest value representable as a normal floating point number in the target datatype.[1] arithmetic underflow - wikipedia floating point - what is the range of values a float can have in python? - stack overflow in naive bayes, i think it would affect the comparison, as probabilities that are actually different would end up being 0 and look equal.",s_answer
151,54,https://piazza.com/class/ky7ls2h92kpwe/post/54,"logistic regression robustness to correlated features.in the logistic regression reading material, under the section 5.2.4 (choosing a classifier), it says logistic regression is more robust to correlated features : ""if two features f1 and f2 are perfectly correlated, regression will simply assign part of the weight to w1 and part to w2"" . is not the test for correlated features (test for multi-collinearity) an important step that we check before building the model ? as, the independence of two features is very important criteria in finding the partial gradient ??",question
152,54,https://piazza.com/class/ky7ls2h92kpwe/post/54,"generally yes. one should get rid of correlated features before fitting the model. however, it is always preferred if your model is robust to these without expert intervention.in addition, it is not always feasible to remove correlated features, e.g. due to limitations of the data or bias in the data. no training data is perfect, especially in nlp.",i_answer
153,18,https://piazza.com/class/ky7ls2h92kpwe/post/18,emojis.are emojis considered to be part of nlp? it feels like it would be a relevant factor — such as for sentiment analysis.,question
154,18,https://piazza.com/class/ky7ls2h92kpwe/post/18,"not sure if i understand the question. so please correct me if i missed it. is your question ""can processing emojis be done as part of nlp? especially for your assignment."" then yes it can be. just think of what you want to do with them as i have seen several research papers and projects on the topic. however, if you are asking ""are emojis a natural language?"". here is my opinion and others can join the discussion as well. i believe yes, emojis are a natural language. although they are manufactured originally, they have evolved naturally in human communities by repetition without conscious planning way beyond their original design. i found this interesting article on the topic:",i_answer
155,871,https://piazza.com/class/ky7ls2h92kpwe/post/871,question 47.question 47 which of the following cannot be fine-tuned into an abstractive summarization model? 3 selected answer: @ transformer encoder-decoder answers: @ bert bart 15 transformer encoder-decoder,question
156,870,https://piazza.com/class/ky7ls2h92kpwe/post/870,question 32.question 32 which of the following can be a (eey=eeonn selected answer: @ fact verification answers: @ abstractive summarization fact verification named entity recognition none of the other choices,question
157,868,https://piazza.com/class/ky7ls2h92kpwe/post/868,question 15.question 15 ‘syntactic ambiguity describes the situation where a string of words: 3 selected answer: ¢ can have more than one meaning answers: cannot be interpreted using syntactic rules can have more than one meaning @ can correspond to more than one structure can have dozens of implau,question
158,861,https://piazza.com/class/ky7ls2h92kpwe/post/861,"exam question 26.question 26 0 out of 1 points if we plan to train a readability analysis model that decides how difficult a given paragraph reads, where the readability is scaled into ix] five levels {very easy, easy, normal, difficult, very difficult}, then which of the following model is not suitable for this task? selected answer: ¢ a multi-class classifier answers: @ aregressor with mae loss an ordinal regression model amulti-class classifier a label ranker",question
159,861,https://piazza.com/class/ky7ls2h92kpwe/post/861,how would you train a sentiment classifier for movie reviews?,i_answer
160,861,https://piazza.com/class/ky7ls2h92kpwe/post/861,"yeah. but, if we can use an ordinary regression model, why cannot we use a regressor with mae loss? i think we only need to change the loss function to mae loss.",followup_question
161,861,https://piazza.com/class/ky7ls2h92kpwe/post/861,because ordinal regression is actually a classification method. it optimizes the probability of the class being leq than each ordinal label. how would you change this objective to mae?,feedback
162,861,https://piazza.com/class/ky7ls2h92kpwe/post/861,by the way. i just exempted this question for all. i agree that a multi-class classifier is also not the best kind of solution.,feedback
163,861,https://piazza.com/class/ky7ls2h92kpwe/post/861,"thank you, professor. i have a follow up question. what do you think is the best solution for this problem?",feedback
164,861,https://piazza.com/class/ky7ls2h92kpwe/post/861,could be ordinary regression.,feedback
165,861,https://piazza.com/class/ky7ls2h92kpwe/post/861,thank you very much!,feedback
166,627,https://piazza.com/class/l7102doc7aa3ob/post/627,"quiz 8.question 8 0 out of 10 points one of the difference between rule-based and transfer-based machine translation is that transfer-based machine translation's rules on semantic structure is more generalizable. selected answer: €3 true answers: true @ false question 4 0 out of 10 points in ibm machine translation model, if there are k words in the source sentence and v words in target sentence in a pair in parallel corpus, how many possible alignments 13] exists in this pair. (a*b means a to the power of b) selected answer: ¢ (v+1)4k answers: k4v (v+41)4k @ (k+1)4v v‘k preriwll weuwviu vi lf = bllitreliaeinte prweieie analignment a is {a1,...@m} ,where a; € {0...1} hence there are (/ + 1)” possible alignments m-.. t{re nr arrrrfri",question
167,627,https://piazza.com/class/l7102doc7aa3ob/post/627,"completely agree with you on transfer-based machine translation problem. for the ibm model problem, this is my understanding: in the ppt you screenshot, l is the length of the source and m is the length of the target, therefore (l+1)^m possible alignments. - for clarification: the slide states, ""[a]n alignment map determines which english word each french word originated from."" meaning that the french word (target) came from the english word (source). (i honestly may be confusing this though.) in the quiz, k is the length of the source and v is the length of the target, therefore (k+1)^v possible alignments..",s_answer
168,627,https://piazza.com/class/l7102doc7aa3ob/post/627,"for question 8, the question is talking about the semantic structure and not the syntactic structure. hence, this will be false!",followup_question